---
title: "Predicting and Preventing Employee Turnover through HR Analytics"
subtitle: ""
author: Guillermo Gallardo
date: "`r Sys.Date()`"
format:
  docx:
    toc: false
    number-sections: true
    highlight-style: github
bibliography: ../../assets/dataanalysis-references.bib
csl: ../../assets/apa.csl
---

```{r, echo=FALSE, message=FALSE}
# load a few R packages
library(here)
library(knitr)

#hr_data = read.csv("C:/Users/crew_/OneDrive/Escritorio/Guille/UTSA Masters/MSDA/DA6833/PracticumII-Course/guillermogallardo-final-project/data/raw-data/IBM HR Analytics Data.csv", header = TRUE) #not synced with OneDrive but my computer added that folder when I entered my email when I bought the computer
```

# Project Overview

The primary objective of this project is to identify the key factors contributing to employee turnover and to develop a model that can predict potential departures within a company. By anticipating these departures, we can create strategies for employee retention and enhance the overall employee experience.

I find this dataset interesting, as it aligns with my previous experience in HR Analytics. Although I've worked in this field before, I never had the opportunity to work on project where we could predict attrition. This project allows me to deep dive into the data I am interested about, while also enhancing my skills in modeling using R.

# Project Question

We have two main questions that we want to answer during this project.

-   What are the primary factors that contribute to employee attrition?

-   What strategies can be implement to enhance employee retention and improve the overall employee experience?

# Dataset

For this project, I was looking for a dataset with employee data that included a wide range of variables to explore potential relationships with attrition. Below, I will provide an overview of the dataset's origin, author, the types of variables it includes, and other relevant details.

## **IBM HR Analytics Employee Attrition**

The dataset for this project was sourced from [Kaggle.com](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset) and was created by IBM Data Scientists as a fictional representation of HR data. It consists of 1,470 rows and 35 variables that cover demographic details, job characteristics, compensation, performance metrics, and employee satisfaction data. This data serves as the foundation for analyzing factors contributing to employee turnover and developing a predictive model.

# Data Cleaning Process

Data cleaning is an important step in data analysis process and focuses on detecting and correcting errors and inconsistencies in the dataset. The goals is to ensure that the data is accurate, complete and reliable. Overall, this dataset didn't have any anomalies and there were only a couple of steps I took to prepare the data. The steps we took are the following:

**Loading Data for Cleaning Process**

In order to start the cleaning process, we need make to sure we load the data. In the code below, we use the *library(here)* function to set the file path dynamically, so our script can find and access the data files regardless of the current working directory.

```{r, message=FALSE}
#| echo: false
library(here)
library(dplyr)
```

```{r, results='hide'}
hr_data = here::here("data","raw-data","IBM HR Analytics Data.xlsx")
rawdata = readxl::read_excel(hr_data)
```

**Removing Column**

In the next step of my data cleaning process, I removed three columns from the dataset. The columns we removed are *DailyRate*, *HourlyRate* and *MonthlyRate.* These columns were removed because the numbers they contained did not align logically or meaningfully. Upon further investigation, it became evident that there was no clear resolution to these discrepancies in Kaggle, and many suggested focusing instead on the Monthly Income field to maintain data consistency and reliability.

```{r, results='hide'}
d1 = rawdata %>% 
  select(-DailyRate, -HourlyRate, -MonthlyRate)

head(d1)
```

**Adding Labels**

Next, we addressed the *Education* field as the third step in our process. Initially numeric, it contained values ranging from 1 to 5. Using our data dictionary, we updated these numeric values to their corresponding labels. This adjustment enhances our understanding of employee education levels in the dataset and ensures consistency in the data.

```{r, results='hide'}
d2 = d1 %>% 
    mutate(Education = case_when(
    Education == 1 ~ "Below College",
    Education == 2 ~ "College",
    Education == 3 ~ "Bachelor's",
    Education == 4 ~ "Master's",
    Education == 5 ~ "Doctorate",
    TRUE ~ as.character(Education)
  ))

head(d2)
```

**Saving File**

The final step in this process involved saving the file as an RDS file. This ensures that we can use it for our exploratory data analysis and maintain an organized project that is reproducible.

```{r, results='hide'}
HRprocesseddata = d2

save_data_location = here::here("data","processed-data","HRprocesseddata.rds")
saveRDS(HRprocesseddata, file = save_data_location)
```

# Analysis Methods

## Exploratory Data Analysis

I am starting my exploratory data analysis project with the objective of summarizing the dataset. I will begin by providing a concise overview of the variables included. Additionally, I will generate plots and tables to identify any outliers or patterns within the dataset. This analysis will help us understand the data available to us and guide our strategy to predict employee attrition within the organization.

### Data Variables

This dataset contains 35 variables, consisting of both character and integer types, with several character variables categorized as categorical. It provides valuable insights into employees, including demographic information such as age, gender, and marital status. Additionally, it offers details about their employment, including monthly income, department, and tenure, which are crucial for understanding their professional profiles and organizational dynamics.

```{r}
#| label: col-hrprocessingdata
#| tbl-cap: "HR Data Variables"
#| echo: FALSE
variables=readRDS("../../results/tables/HRvariablestable.rds")
knitr::kable(variables)
```

### **Gender** 

The dataset consists of 1470 employees, with a gender distribution showing that males constitute the majority at 60%, while females make up 40%.

**Distribution**

```{r}
#| label: col-hrgender
#| tbl-cap: "Employee Gender"
#| echo: FALSE
gender_table=readRDS("../../results/tables/HRgendertable.rds")
knitr::kable(gender_table)
```

### **Employee Tenure (in years)**

I examined the distribution of employee tenure and identified two distinct peaks: one at 5 years and another at 1 year. This provide quick insights into the typical duration of employees within the organization, and help us identify patterns that may influence employees to resign.

```{r}
#| label: fig-tenure
#| fig-cap: "Employee Tenure"
#| echo: FALSE
knitr::include_graphics(here("results","figures","tenure-distribution.png"))
```

**MAYBE ADD LABEL FOR TENURE?**

### **Education** MOVE TO EDA

During data cleaning, we'll use the data dictionary to decode each field. For instance, the education field is labeled from 1 to 5, representing different educational levels: 1 = "Below College," 2 = "College," 3 = "Bachelor's," 4 = "Master's," and 5 = "Doctorate." Notably, about 40% of the dataset holds a Bachelor's degree.

```{r }

```

## Correlation Analysis

As we explore various analysis methods in our class, my focus is on finding potential correlation between variables and employee attrition. I am interested in using the demographic details, job attributes and survey data to uncover pattern (if any) that highlight this issue .

## Predictive Modeling

My main goal is to predict when an employee might leave the company. I am interested in using predictive modeling techniques (also part of my other summer class) to see if we can predict attrition. Once I've identified potential departures, we can use this findings to create strategies to prevent or reduce attrition.
